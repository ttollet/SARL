# Determines function call
algorithm: ???
environment: ???

parameters:
  train_episodes: 300032 #250 # default: 2500; used only by temp_pdqn.py
  max_steps: 500 #250
  learning_steps: 300032 #400000  # Multiple of on_policy_params.n_steps
  cycles: 128 #20 # Factor of learning_steps
  seeds:
    - 1
    # - 2
    # - 3
    # - 4
    # - 5
    # - 6
    # - 7
    # - 8
    # - 9
    # - 10
    # - 11
    # - 12
    # - 13
    # - 14
    # - 15
  eval_episodes: 250
  alg_params:
    discrete_learning_rate: 0.1
    continuous_learning_rate: 0.1
    update_ratio: 0.5
    on_policy_params:
      n_steps: 2048

verbose: info
hydra:
  job:
    name: unnamed
  run:
    # dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S_}${hydra.job.name}
  runtime:
    # dir: outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
    output_dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S_}${hydra.job.name}
